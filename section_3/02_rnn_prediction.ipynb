{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgElYfXaPOCj3AM0d0prT8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_stock_prediction/blob/main/section_3/02_rnn_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AIによる株価予測（LSTM版）（データの取得・学習・推論）\n",
        "ここではモデル定義クラス LSTMNet を作成し、時系列の順序を保ったまま学習を行います。"
      ],
      "metadata": {
        "id": "XwoF5HHsl1ji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh8K7m5kYQkg"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインストールとインポート\n",
        "# !pip install -q yfinance\n",
        "\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- 設定 ---\n",
        "STOCK_CODE = '7203.T'  # 予測対象（例: トヨタ自動車）\n",
        "START_DATE = '2020-01-01'\n",
        "END_DATE = '2024-12-31'\n",
        "WINDOW_SIZE = 15     # 過去30日分のデータから翌日を予測\n",
        "TEST_RATIO = 0.2\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_SIZE = 64     # LSTMの隠れ層のニューロン数\n",
        "NUM_LAYERS = 2       # LSTMの層の数\n",
        "\n",
        "# 1. データの取得と前処理\n",
        "print(\"データを取得中...\")\n",
        "df = yf.download(STOCK_CODE, start=START_DATE, end=END_DATE, progress=False)\n",
        "\n",
        "# 株価の「変動率（リターン）」を計算\n",
        "data = df['Close'].pct_change().dropna().values.reshape(-1, 1)\n",
        "\n",
        "# データの正規化\n",
        "scaler = StandardScaler()\n",
        "data_normalized = scaler.fit_transform(data)\n",
        "\n",
        "# データセットの作成関数\n",
        "def create_dataset(dataset, window_size):\n",
        "    X, y = [], []\n",
        "    for i in range(len(dataset) - window_size):\n",
        "        feature = dataset[i:i + window_size]\n",
        "        target = dataset[i + window_size]\n",
        "        X.append(feature)\n",
        "        y.append(target)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_dataset(data_normalized, WINDOW_SIZE)\n",
        "\n",
        "# 学習用とテスト用に分割\n",
        "split_index = int(len(X) * (1 - TEST_RATIO))\n",
        "X_train, y_train = X[:split_index], y[:split_index]\n",
        "X_test, y_test = X[split_index:], y[split_index:]\n",
        "\n",
        "# PyTorchのTensorに変換\n",
        "# LSTMへの入力形状は (Batch_Size, Sequence_Length, Input_Size) です\n",
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "y_test_tensor = torch.from_numpy(y_test).float()\n",
        "\n",
        "# データローダーの作成\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# 2. LSTMモデルの定義\n",
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size=1):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # batch_first=True にすると (batch, seq, feature) で入出力できる\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, window_size, input_size)\n",
        "        # 初期隠れ状態とセル状態を初期化（デバイス合わせ）\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # LSTMへ通す\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # out[:, -1, :] : 最後のタイムステップの出力のみを取り出す\n",
        "        # 多対一 (Many-to-One) の予測のため\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 入力サイズは1（変動率という1つの特徴量のみ）\n",
        "model = LSTMNet(input_size=1, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS).to(device)\n",
        "\n",
        "# 損失関数と最適化手法\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 3. 学習ループ\n",
        "print(\"LSTMモデルの学習を開始します...\")\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.6f}')\n",
        "\n",
        "print(\"学習完了。\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.title('Training Loss (LSTM)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 予測結果の評価 その1（視覚化と誤差の計算）"
      ],
      "metadata": {
        "id": "1EMq9hOMmEZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価モードへ\n",
        "model.eval()\n",
        "\n",
        "# 推論の実行\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_tensor.to(device)).cpu().numpy()\n",
        "\n",
        "# 正規化を元に戻す\n",
        "predictions_actual = scaler.inverse_transform(predictions)\n",
        "y_test_actual = scaler.inverse_transform(y_test)\n",
        "\n",
        "# グラフによる可視化（直近100日分）\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(y_test_actual[-100:], label='Actual Return', color='blue', alpha=0.6)\n",
        "plt.plot(predictions_actual[-100:], label='Predicted Return (LSTM)', color='green', alpha=0.7)\n",
        "\n",
        "plt.title(f'{STOCK_CODE} Return Prediction with LSTM (Last 100 Days)')\n",
        "plt.xlabel('Time (Days)')\n",
        "plt.ylabel('Return Rate')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 誤差の計算\n",
        "rmse = np.sqrt(np.mean((predictions_actual - y_test_actual)**2))\n",
        "print(f\"Test RMSE (LSTM): {rmse:.6f}\")"
      ],
      "metadata": {
        "id": "pYm-68GgYyaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 予測結果の評価 その2（投資シミュレーション）"
      ],
      "metadata": {
        "id": "hecSjf6SmezL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 投資シミュレーション\n",
        "initial_capital = 100000.0\n",
        "\n",
        "# LSTM戦略\n",
        "lstm_capital = [initial_capital]\n",
        "current_lstm_capital = initial_capital\n",
        "\n",
        "# ガチホ戦略\n",
        "hold_capital = [initial_capital]\n",
        "current_hold_capital = initial_capital\n",
        "\n",
        "for i in range(len(y_test_actual)):\n",
        "    actual_return = y_test_actual[i][0]\n",
        "    predicted_return = predictions_actual[i][0]\n",
        "\n",
        "    # LSTMが「上がる」と予測した場合のみ投資\n",
        "    if predicted_return > 0:\n",
        "        current_lstm_capital = current_lstm_capital * (1 + actual_return)\n",
        "\n",
        "    lstm_capital.append(current_lstm_capital)\n",
        "\n",
        "    # ガチホは常に投資\n",
        "    current_hold_capital = current_hold_capital * (1 + actual_return)\n",
        "    hold_capital.append(current_hold_capital)\n",
        "\n",
        "# 結果の可視化\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(lstm_capital, label='AI Strategy (LSTM)', color='green')\n",
        "plt.plot(hold_capital, label='Buy & Hold Strategy', color='blue', linestyle='--')\n",
        "\n",
        "plt.title('Investment Simulation: LSTM vs Buy & Hold')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Portfolio Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"最終資産 (Buy & Hold): {hold_capital[-1]:.2f}\")\n",
        "print(f\"最終資産 (AI Strategy - LSTM): {lstm_capital[-1]:.2f}\")\n",
        "\n",
        "if lstm_capital[-1] > hold_capital[-1]:\n",
        "    print(\"結果: LSTMモデルが市場平均を上回りました。\")\n",
        "else:\n",
        "    print(\"結果: LSTMモデルは市場平均に及びませんでした。\")"
      ],
      "metadata": {
        "id": "P5KondKtY11d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}